{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecmwf.opendata import Client\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.feature as cfeature\n",
    "from datetime import datetime, timedelta\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.tri import Triangulation\n",
    "import matplotlib.ticker as ticker\n",
    "import shapely.speedups\n",
    "from shapely import Polygon\n",
    "import subprocess\n",
    "from dataclasses import dataclass\n",
    "import xarray as xr\n",
    "import cfgrib\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.transform import from_bounds\n",
    "from rasterio.crs import CRS\n",
    "#import h3\n",
    "from pyproj import Transformer\n",
    "import json\n",
    "import pprint\n",
    "#import dask\n",
    "import eccodes\n",
    "import pygrib\n",
    "import psycopg2\n",
    "from osgeo import gdal\n",
    "from collections import defaultdict\n",
    "from scipy.spatial import KDTree\n",
    "from itertools import chain\n",
    "\n",
    "@dataclass\n",
    "class DateTimeParts:\n",
    "    year: int\n",
    "    month: int\n",
    "    day: int\n",
    "    hour: int\n",
    "    month_str: str\n",
    "    day_str: str\n",
    "    hour_str: str\n",
    "    date_str: str\n",
    "\n",
    "    @classmethod\n",
    "    def from_datetime(cls, dt: datetime):\n",
    "        month_str=str(dt.month).zfill(2)\n",
    "        day_str = str(dt.day).zfill(2)\n",
    "        hour_str=str(dt.hour).zfill(2)\n",
    "        date_str = str(dt.year)+month_str+day_str\n",
    "        return cls(year=dt.year, month=dt.month, day=dt.day, hour=dt.hour, month_str=month_str, day_str=day_str, hour_str=hour_str, date_str=date_str)\n",
    "    \n",
    "def windCalc(u,v):\n",
    "        #print('windCalc Function')\n",
    "        wind_abs = np.sqrt(u**2 + v**2)\n",
    "        wind_dir_trig_to = np.arctan2(u/wind_abs, v/wind_abs)\n",
    "        wind_dir_trig_to_degrees = wind_dir_trig_to * 180/np.pi ## -111.6 degrees\n",
    "        wind_dir = wind_dir_trig_to_degrees + 180\n",
    "        return wind_abs * 2.23694 #TO MPH\n",
    "def K_to_F(temp):\n",
    "    temp = ((temp - 273.15) * (9/5)) + 32\n",
    "    return temp\n",
    "\n",
    "def F_to_K(temp):\n",
    "    temp = ((temp - 32) * 5/9) + 273.15\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(source='aws')\n",
    "\n",
    "latestrun = client.latest(\n",
    "    #stream='enfo',\n",
    "    step=[144],\n",
    "    type=\"fc\", #fc for HRES fcst #pf for perterbed fcst\n",
    "    #param=[\"msl\", \"2t\", \"10u\", \"10v\", \"100u\", \"100v\", \"tp\"],\n",
    "    #param = ['mx2t6','mn2t6'],\n",
    "    param = ['2t'],\n",
    ")\n",
    "\n",
    "latestrun.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(source='ecmwf')\n",
    "target_test = 'data/gribs/ecmwf/maxmin/ecmwf-latest_test.grib'\n",
    "\n",
    "curtime = datetime.now()\n",
    "if curtime.hour < 4:\n",
    "    curtime = curtime - timedelta(days=1)\n",
    "    day_str = f'{curtime.year}{str(curtime.month).zfill(2)}{str(curtime.day).zfill(2)}'\n",
    "    hour = 12\n",
    "    print(day_str, curtime.hour)\n",
    "    step = list(range(12,144,3))\n",
    "    client.retrieve(\n",
    "    time=hour,\n",
    "    date=day_str,\n",
    "    #stream='enfo',\n",
    "    step=step,\n",
    "    type=\"fc\", #fc for HRES fcst #pf for perterbed fcst\n",
    "    #param=[\"msl\", \"2t\", \"tp\"],\n",
    "    param=[\"10u\", \"10v\", \"100u\", \"100v\"],\n",
    "    #param = ['mx2t6','mn2t6'],\n",
    "    #param = ['2t'],\n",
    "    target=target_test,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    latest= client.latest(\n",
    "        #stream='enfo',\n",
    "        step=[144],\n",
    "        type=\"fc\", #fc for HRES fcst #pf for perterbed fcst\n",
    "        #param=[\"msl\", \"2t\", \"10u\", \"10v\", \"100u\", \"100v\", \"tp\"],\n",
    "        #param = ['mx2t6','mn2t6'],\n",
    "        param = ['2t'],\n",
    "    )\n",
    "    latest = latest.hour\n",
    "\n",
    "    print(latest)\n",
    "\n",
    "    ens_range = chain(range(12,144,3),range(150,361,6))\n",
    "    if latest in [6,18]:\n",
    "        ens_range = range(12,144,3)\n",
    "    step = list(ens_range)\n",
    "    client = Client(source='aws')\n",
    "    client.retrieve(\n",
    "        #stream='enfo',\n",
    "        step=step,\n",
    "        type=\"fc\", #fc for HRES fcst #pf for perterbed fcst\n",
    "        param=[\"msl\", \"2t\", \"tp\"],\n",
    "        param=[\"10u\", \"10v\", \"100u\", \"100v\"],\n",
    "        #param = ['mx2t6','mn2t6'],\n",
    "        #param = ['2t'],\n",
    "        target=target_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step = list(range(12,361,6))\n",
    "ens_range = chain(range(12,144,3),range(150,361,6))\n",
    "ens_range_aifs = range(0,361,6)\n",
    "step = list(ens_range_aifs)\n",
    "target = 'data/gribs/ecmwf-aifs/maxmin/ecmwf-aifs-latest.grib'\n",
    "target2 = '/usr/share/geoserver/data_dir/data/ecmwf/ecmwf_latest.grib'\n",
    "client = Client(source='ecmwf')\n",
    "#step=[360]\n",
    "client.retrieve(\n",
    "    time=12,\n",
    "    date=20241120,\n",
    "    model=\"aifs\",\n",
    "    #stream='enfo',\n",
    "    step=step,\n",
    "    type=\"fc\", #fc for HRES fcst #pf for perterbed fcst\n",
    "    param = ['2t'],\n",
    "    target=target,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'ecmwf-aifs'\n",
    "#gribfile = f'data/gribs/{model.lower()}/latest/{model.lower()}-024.grb2'\n",
    "#latestGrb = f'data/gribs/{model.lower()}/latest/{model.lower()}-latest.grib'\n",
    "latestGrb = f'data/gribs/{model.lower()}/maxmin/{model.lower()}-latest.grib'\n",
    "gribfile = latestGrb\n",
    "grbs = pygrib.open(gribfile)\n",
    "for grb in grbs:\n",
    "    print(grb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gribfile = f'data/gribs/{model.lower()}/maxmin/{model.lower()}-240.grb2'\n",
    "grbs = pygrib.open(gribfile)\n",
    "try:\n",
    "    tgrb_max = grbs.select(name = 'Maximum temperature')\n",
    "except:\n",
    "    tgrb_max = []\n",
    "try:\n",
    "    tgrb_min = grbs.select(name = 'Minimum temperature')\n",
    "except:\n",
    "    tgrb_min = []\n",
    "tempgrbs_max = (tgrb_max)\n",
    "for  tmp in tempgrbs_max:\n",
    "    print(tmp)\n",
    "tempgrbs_min = (tgrb_min)\n",
    "for  tmp in tempgrbs_min:\n",
    "    print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tgrb = grbs.select(shortName = '2t')\n",
    "tgrb = grbs.select(name = 'Maximum temperature')\n",
    "#tgrb = grbs.select(paramId = 167) #t2 ens std\n",
    "tsd = (tgrb[3])\n",
    "tsd4 = (tgrb[4])\n",
    "print(tsd)\n",
    "print(tsd4)\n",
    "print(dir(tsd))\n",
    "print(tsd.validDate)\n",
    "tsd_list = list(dir(tsd))\n",
    "tsd_keys = (tsd.keys())\n",
    "print('2 metre temperature:K (instant):lambert:heightAboveGround:level 2 m:fcst time 36 hrs:from 202410151900:ens std dev')\n",
    "for key in tsd_list:\n",
    "    try:\n",
    "        print(key, tsd[key])\n",
    "    except:\n",
    "        print(key, ' does not exist')\n",
    "print('****************************************************')\n",
    "print('2 metre temperature:K (instant):lambert:heightAboveGround:level 2 m:fcst time 36 hrs:from 202410151900')\n",
    "tsd4_list = list(dir(tsd4))\n",
    "tsd4_keys = (tsd4.keys())\n",
    "for key4 in tsd4_list:\n",
    "    try:\n",
    "        print(key4, tsd4[key4])\n",
    "    except:\n",
    "        print(key4, ' does not exist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grb1 = grbs[1]\n",
    "print(grb1)\n",
    "lats, lons = grb1.latlons()\n",
    "# Flatten the lat/lon arrays to create a 2D list of points\n",
    "grid_points = np.column_stack((lats.ravel(), lons.ravel()))\n",
    "\n",
    "# Build a KDTree from the lat/lon grid\n",
    "tree = KDTree(grid_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createOutput(var, nearest_indices, df_coords):   \n",
    "    data = {icao: [] for icao in df_coords['ICAO']}\n",
    "    grbs_all = pygrib.open(gribfile)\n",
    "    #tgrb = grbs_all.select(shortName = '2t')\n",
    "    tgrb = grbs.select(name=var)\n",
    "    tempgrbs = tgrb\n",
    "\n",
    "    # Loop through the GRIB messages to extract data for all variables and times\n",
    "    for grb in tempgrbs:\n",
    "        print(grb)\n",
    "        var_name = grb.name\n",
    "        valid_time = grb.validDate\n",
    "\n",
    "        # Flatten the data grid to align with the grid points\n",
    "        data_values = (K_to_F(grb.values.ravel()).round(0))\n",
    "\n",
    "        # For each row in the DataFrame, get the value from the nearest grid point\n",
    "        for (icao, idx) in zip(df_coords['ICAO'], nearest_indices):\n",
    "            nearest_value = data_values[idx]\n",
    "\n",
    "            # Collect the value, time, and variable for the given ICAO\n",
    "            data[icao].append({\n",
    "                'time': valid_time,\n",
    "                'variable': var_name,\n",
    "                'value': int(nearest_value),\n",
    "                'lat': df_coords.loc[df_coords['ICAO'] == icao, 'lat'].values[0],\n",
    "                'lon': df_coords.loc[df_coords['ICAO'] == icao, 'lon'].values[0],\n",
    "                'city': df_coords.loc[df_coords['ICAO'] == icao, 'CITY'].values[0],  # Add city\n",
    "                'state': df_coords.loc[df_coords['ICAO'] == icao, 'STATE'].values[0]  # Add state\n",
    "            })\n",
    "\n",
    "    # Create an empty list to store rows for the DataFrame\n",
    "    trows = []\n",
    "\n",
    "    # Flatten the data dictionary into the list of rows\n",
    "    for icao, records in data.items():\n",
    "        for record in records:\n",
    "            # Append each record as a dictionary to the rows list\n",
    "            trows.append({\n",
    "                'ICAO': icao,\n",
    "                'time': record['time'],\n",
    "                'variable': record['variable'],\n",
    "                'value': record['value'],\n",
    "                'lat': record['lat'],\n",
    "                'lon': record['lon'],\n",
    "                'CITY': record['city'],  # Add city to DataFrame\n",
    "                'STATE': record['state']  # Add state to DataFrame\n",
    "            })\n",
    "    print(trows)\n",
    "\n",
    "    # Convert the list of rows into a DataFrame\n",
    "    result_df = pd.DataFrame(trows)\n",
    "\n",
    "    # The final DataFrame contains the time series for each ICAO code\n",
    "    print(result_df)\n",
    "\n",
    "    features = []\n",
    "    for icao, records in data.items():\n",
    "        # Extract lat/lon from one of the records (all will have the same lat/lon for the same ICAO)\n",
    "        lat = records[0]['lat']\n",
    "        lon = records[0]['lon']\n",
    "        city = records[0]['city']  # Extract city\n",
    "        state = records[0]['state']  # Extract state\n",
    "\n",
    "        # Prepare time series for this ICAO\n",
    "        time_series = [{\n",
    "            'time': str(record['time']),\n",
    "            'variable': str(record['variable']),\n",
    "            'value': str(record['value'])\n",
    "        } for record in records]\n",
    "\n",
    "        # Create the GeoJSON feature for this ICAO with the time series\n",
    "        feature = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": [str(lon), str(lat)]\n",
    "            },\n",
    "            \"properties\": {\n",
    "                \"ICAO\": icao,\n",
    "                \"CITY\": city,  # Add city to GeoJSON\n",
    "                \"STATE\": state,  # Add state to GeoJSON\n",
    "                \"time_series\": time_series\n",
    "            }\n",
    "        }\n",
    "        features.append(feature)\n",
    "\n",
    "    # Create the final GeoJSON structure\n",
    "    geojson_data = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": features\n",
    "    }\n",
    "\n",
    "    # Determine file name based on the variable type\n",
    "    if var == 'Maximum temperature at 2 metres in the last 6 hours':\n",
    "        var_out = 'maxtemp'\n",
    "    elif var == 'Minimum temperature at 2 metres in the last 6 hours':\n",
    "        var_out = 'mintemp'\n",
    "    elif var == '2 metre temperature':\n",
    "        var_out = 'temp'   \n",
    "    else:\n",
    "        var_out = ''\n",
    "    \n",
    "    # Export to GeoJSON file\n",
    "    \"\"\" with open(f'output_data_{var_out}.geojson', 'w') as f:\n",
    "        json.dump(geojson_data, f, indent=4) \"\"\"\n",
    "    \n",
    "    # Export to GeoJSON file\n",
    "    with open(f'/var/www/fapi/app/static/data/point/ecmwf/output_data_{var_out}.geojson', 'w') as f:\n",
    "        json.dump(geojson_data, f, indent=4)\n",
    "\n",
    "\n",
    "    print(\"GeoJSON with time series exported successfully!\")\n",
    "\n",
    "\n",
    "df_coords = pd.read_csv('stations.csv')\n",
    "coordinates = df_coords[['lat', 'lon']].values\n",
    "nearest_indices = [tree.query([lat, lon])[1] for lat, lon in coordinates]\n",
    "#createOutput('Maximum temperature at 2 metres in the last 6 hours', nearest_indices, df_coords)\n",
    "#createOutput('Minimum temperature at 2 metres in the last 6 hours', nearest_indices, df_coords)\n",
    "createOutput('2 metre temperature', nearest_indices, df_coords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output_data.geojson', 'r') as f:\n",
    "    geojson_data = json.load(f)\n",
    "\n",
    "# Print to check structure\n",
    "#print(json.dumps(geojson_data, indent=4))\n",
    "print(geojson_data['features'])\n",
    "print(geojson_data['features'][-1]['properties'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('stations2.csv')\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Define the custom order for the REGION column\n",
    "regions = ['SOUTH', 'CENTRAL', 'NORTH', 'WEST']\n",
    "\n",
    "# Convert the 'REGION' column to a categorical type with the specified order\n",
    "df['REGION'] = pd.Categorical(df['REGION'], categories=regions, ordered=True)\n",
    "\n",
    "# Sort the DataFrame by 'REGION' (custom order) and 'CITY' (alphabetically)\n",
    "df_sorted = df.sort_values(['REGION', 'CITY'])\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "print(\"Sorted DataFrame by REGION and CITY:\")\n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "print(os.getcwd())\n",
    "print(dir(dt.datetime))\n",
    "print(dir(dt.timedelta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydate = (dt.datetime.now())\n",
    "mydate = dt.datetime(2024,1,1,16)\n",
    "dateparts = DateTimeParts.from_datetime(mydate)\n",
    "print(dateparts)\n",
    "print(dateparts.year)\n",
    "print(dateparts.month_str)\n",
    "print(dateparts.day_str)\n",
    "print(dateparts.hour_str)\n",
    "print(dateparts.date_str)\n",
    "\n",
    "if dateparts.hour >= 2 and dateparts.hour <= 8:\n",
    "    hour_str = '00'\n",
    "elif dateparts.hour >= 9 and dateparts.hour <= 15:\n",
    "    hour_str = '06'\n",
    "elif dateparts.hour >= 16 and dateparts.hour <= 21:\n",
    "    hour_str = '12'\n",
    "elif dateparts.hour >= 22:\n",
    "    hour_str = '18'\n",
    "elif dateparts.hour < 2:\n",
    "    hour_str = '18'\n",
    "    dateparts = DateTimeParts.from_datetime(mydate - dt.timedelta(days=1))\n",
    "else:\n",
    "    print(f'warning: forecast hour {dateparts.hour} is not between 0 and 23')\n",
    "    hour_str = None\n",
    "\n",
    "print('gfs runtime: ', dateparts.date_str, hour_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInitTime_GFS():\n",
    "    mydate = (dt.datetime.now())\n",
    "    dateparts = DateTimeParts.from_datetime(mydate)\n",
    "\n",
    "    if dateparts.hour >= 2 and dateparts.hour <= 8:\n",
    "        hour_str = '00'\n",
    "    elif dateparts.hour >= 9 and dateparts.hour <= 15:\n",
    "        hour_str = '06'\n",
    "    elif dateparts.hour >= 16 and dateparts.hour <= 21:\n",
    "        hour_str = '12'\n",
    "    elif dateparts.hour >= 22:\n",
    "        hour_str = '18'\n",
    "    elif dateparts.hour < 2:\n",
    "        hour_str = '18'\n",
    "        dateparts = DateTimeParts.from_datetime(mydate - dt.timedelta(days=1))\n",
    "    else:\n",
    "        print(f'warning: forecast hour {dateparts.hour} is not between 0 and 23')\n",
    "        hour_str = None\n",
    "\n",
    "    return dateparts, hour_str\n",
    "\n",
    "dateparts, hour_str = getInitTime_GFS()\n",
    "print(dateparts, hour_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dt.datetime.now()\n",
    "\n",
    "filename = f'file {d}.txt'\n",
    "\n",
    "# Write the formatted string to the new file\n",
    "with open(filename, 'w') as file:\n",
    "    file.write(str(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "color_values = {\n",
    "    -30: 'maroon',\n",
    "    -20: 'teal',\n",
    "    -10: 'lavender',\n",
    "    0: 'white',\n",
    "    10: 'fuchsia',\n",
    "    20: 'purple',\n",
    "    30: 'blue',\n",
    "    40: 'aqua',\n",
    "    50: 'green',\n",
    "    60: 'yellow',\n",
    "    70: 'orange',\n",
    "    80: 'red',\n",
    "    90: 'purple',\n",
    "    100: 'white',\n",
    "    110: 'pink',\n",
    "    130: 'maroon'\n",
    "}\n",
    "\n",
    "# Create the normalized bounds (0 to 1) for the colormap\n",
    "norm = mcolors.Normalize(vmin=min(color_values.keys()), vmax=max(color_values.keys()))\n",
    "\n",
    "# Create a LinearSegmentedColormap\n",
    "cmap = mcolors.LinearSegmentedColormap.from_list(\n",
    "    'colormap_tempF',\n",
    "    [(norm(value), color) for value, color in color_values.items()]\n",
    ")\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "color_values_wind = {\n",
    "    0: 'blue',\n",
    "    5: 'aqua',\n",
    "    10: 'yellow',\n",
    "    20: 'orange',\n",
    "    30: 'red',\n",
    "    40: 'pink',\n",
    "    50: 'green',\n",
    "    60: 'brown'\n",
    "}\n",
    "\n",
    "# Create the normalized bounds (0 to 1) for the colormap\n",
    "norm_wind = mcolors.Normalize(vmin=min(color_values_wind.keys()), vmax=max(color_values_wind.keys()))\n",
    "\n",
    "# Create a LinearSegmentedColormap\n",
    "cmap_wind = mcolors.LinearSegmentedColormap.from_list(\n",
    "    'colormap_windms',\n",
    "    [(norm_wind(value), color) for value, color in color_values_wind.items()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = \"data/gribs/ecmwf/maxmin/ecmwf-latest.grib\"\n",
    "\n",
    "grbs = pygrib.open(testfile)\n",
    "print(dir(grbs[1]))\n",
    "for grb in grbs[1:2]:\n",
    "    #print(grb)\n",
    "    print(grb.shortName, grb.typeOfLevel, grb.level)\n",
    "    stepType = grb.stepType\n",
    "    step = grb.step\n",
    "    fhour = grb.validDate\n",
    "    \n",
    "    filter_kwargs = {'stepType' : f'{stepType}', 'step': step}\n",
    "    ds = xr.open_dataset(\n",
    "        testfile,\n",
    "        engine=\"cfgrib\",\n",
    "        backend_kwargs={\"filter_by_keys\": filter_kwargs})\n",
    "    print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "model = 'ecmwf-aifs'\n",
    "cmap_name = 'colormap_tempF'\n",
    "testfile = \"data/gribs/ecmwf/maxmin/ecmwf-latest.grib\"\n",
    "testfile = f'data/gribs/{model}/maxmin/{model}-latest.grib'\n",
    "fapi_root = \"/var/www/fapi/app/\"\n",
    "grbs = pygrib.open(testfile)\n",
    "for grb in grbs[14:15]:\n",
    "    shortname = grb.shortName\n",
    "    longname = grb.name\n",
    "    validDate = grb.validDate\n",
    "    analDate = grb.analDate\n",
    "    fcstHour = grb.forecastTime\n",
    "    level = grb.level\n",
    "    levtype = grb.levtype\n",
    "    typeOfLevel = grb.typeOfLevel\n",
    "    unit = grb.units\n",
    "    cfName = grb.cfVarName\n",
    "    stepType = grb.stepType\n",
    "    step = grb.step\n",
    "    p_units = grb.parameterUnits\n",
    "    print('shortname', shortname)\n",
    "    print('longname', longname)\n",
    "    print('stepType', stepType)\n",
    "    print('step', step)\n",
    "    print('unit', unit)\n",
    "    print('p_unit', p_units)\n",
    "    #step = timedelta(hours=fcstHour)\n",
    "    filter_kwargs = {'stepType' : f'{stepType}', 'step': step}\n",
    "    #filter_kwargs = {'shortName' : f'{shortname}', 'step': step }\n",
    "    ds = xr.open_dataset(\n",
    "        testfile,\n",
    "        engine=\"cfgrib\",\n",
    "        backend_kwargs={\"filter_by_keys\": filter_kwargs})\n",
    "    ds=ds.sel(latitude = slice(57,20), longitude= slice(-130,-65))\n",
    "    \n",
    "    #ds = ds.sel(step=step)\n",
    "    #print(ds)\n",
    "    variables = list(ds.data_vars)\n",
    "    variable = ds[variables[0]]\n",
    "    variable = variable.rio.write_crs(\"EPSG:4326\")\n",
    "    variable.attrs['units'] = p_units\n",
    "    variable = variable.metpy.quantify() \n",
    "    variable_F = variable.metpy.convert_units('degF')\n",
    "    fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    #contour = variable_F.plot(ax=ax, transform=ccrs.PlateCarree(), vmin=-30, vmax=130, cmap=cmap)\n",
    "    #contour = ax.contourf(variable.longitude, variable.latitude, variable_F.values, transform=ccrs.PlateCarree(), levels = 32, vmin=-30, vmax=130, cmap=cmap)\n",
    "    #contour = ax.pcolormesh(variable.longitude, variable.latitude, variable_F.values, transform=ccrs.PlateCarree(), vmin=-30, vmax=130, cmap=cmap, shading='gouraud')\n",
    "    contour = ax.contourf(variable.longitude, variable.latitude, variable_F.values, transform=ccrs.PlateCarree(), levels=161, vmin=-30, vmax=130, cmap=cmap)\n",
    "    ax.add_feature(cfeature.STATES)\n",
    "    ax.coastlines()\n",
    "    cbar = fig.colorbar(contour, shrink=1.0, orientation='horizontal', pad=0.03, aspect=60)\n",
    "    cbar.ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "    #colorbar = contour.colorbar\n",
    "    #colorbar.ax.set_position([0.78, 0.3, 0.03, 0.4])\n",
    "    #ax.set_extent([-130, -65, 20, 50])\n",
    "    time_init = pd.Timestamp(ds.time.values).strftime('%D %H')\n",
    "    time_valid = pd.Timestamp(ds.valid_time.values).strftime('%a %D %H')\n",
    "    #plt.title(f\"ECMWF {level}m wind mph {time_init}Z fcst hr {step} {time_valid}Z\")\n",
    "    extents = {\n",
    "        'conus': [-130, -65, 20, 50],       # Global extent\n",
    "        'central': [-105, -85, 28, 50],     # Regional extent\n",
    "        'sc_plains': [-103, -95, 33, 39]          # Another regional extent\n",
    "        }\n",
    "    extents2 = {\n",
    "        'central': [-103, -95, 33, 39]\n",
    "        }\n",
    "        #ax.set_extent([-130, -65, 20, 50])\n",
    "        \n",
    "    for region, extent in extents.items():\n",
    "        ax.set_extent(extent)\n",
    "        plt.title(f\"{model.upper()} {shortname} deg F {time_init}Z fcst hr {step} {time_valid}Z\")\n",
    "        fapi_filename = f\"static/data/plots/{model}/{model}_{region}_{shortname}_{str(step).zfill(3)}.png\"\n",
    "        fapi_path = f\"{fapi_root}{fapi_filename}\"\n",
    "        plt.savefig(f\"data/images/{model}_plot/{model}_{region}_{shortname}_{str(step).zfill(3)}.png\", bbox_inches='tight', pad_inches=0.1)\n",
    "        plt.savefig(fapi_path, bbox_inches='tight', pad_inches=0.1)\n",
    "        #plt.savefig(f\"data/images/{model}_plot/{model}_{shortname}_{str(step).zfill(3)}.png\", bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = \"data/gribs/ecmwf/maxmin/ecmwf-latest_test.grib\"\n",
    "testfile = target\n",
    "step_list = []\n",
    "grbs = pygrib.open(testfile)\n",
    "for grb in grbs:\n",
    "    step_list.append(grb.step)\n",
    "step_list = sorted(step_list)\n",
    "steps = list(dict.fromkeys(step_list))\n",
    "print(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = \"data/gribs/ecmwf/maxmin/ecmwf-latest_test.grib\"\n",
    "grbs = pygrib.open(testfile)\n",
    "for step in list(steps)[1:3]:\n",
    "    for level in [10,100]:\n",
    "        print(step)\n",
    "        grb = grbs.select(step=step, level=level)\n",
    "        print(dir(grb[0]))\n",
    "        shortname = grb.shortName\n",
    "        print(shortname)\n",
    "        filter_kwargs = {'level': level, 'step':step}\n",
    "        ds = xr.open_dataset(\n",
    "            testfile,\n",
    "            engine=\"cfgrib\",\n",
    "            backend_kwargs={\"filter_by_keys\": filter_kwargs})\n",
    "        print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_wind = gp.read_file('windfarms1000.shp')\n",
    "print(gdf_wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "testfile = \"data/gribs/ecmwf/maxmin/ecmwf-latest_test.grib\"\n",
    "grbs = pygrib.open(testfile)\n",
    "for step in list(steps)[1:2]:\n",
    "    for level in [10,100]:\n",
    "        grb = grbs.select(step=step, level=level)[0]\n",
    "        print(grb)\n",
    "        filter_kwargs = {'level': level, 'step':step}\n",
    "        print(dir())\n",
    "        shortname = grb.shortName\n",
    "        longname = grb.name\n",
    "        validDate = grb.validDate\n",
    "        analDate = grb.analDate\n",
    "        fcstHour = grb.forecastTime\n",
    "        level = grb.level\n",
    "        levtype = grb.levtype\n",
    "        typeOfLevel = grb.typeOfLevel\n",
    "        unit = grb.units\n",
    "        cfName = grb.cfVarName\n",
    "        stepType = grb.stepType\n",
    "        step = grb.step\n",
    "        p_units = grb.parameterUnits\n",
    "        print('shortname', shortname)\n",
    "        print('longname', longname)\n",
    "        print('stepType', stepType)\n",
    "        print('timeinit',analDate)\n",
    "        print('step', step)\n",
    "        print('unit', unit)\n",
    "        print('p_unit', p_units)\n",
    "        #step = timedelta(hours=fcstHour)\n",
    "        #filter_kwargs = {'stepType' : f'{stepType}', 'step': step}\n",
    "        #filter_kwargs = {'shortName' : f'{shortname}', 'step': step }\n",
    "        ds = xr.open_dataset(\n",
    "            testfile,\n",
    "        engine=\"cfgrib\",\n",
    "        backend_kwargs={\"filter_by_keys\": filter_kwargs})\n",
    "        ds1=(ds.sel(latitude = slice(62,15), longitude= slice(-140,-55))).coarsen(latitude=2, longitude=2, boundary='trim').mean()\n",
    "        ds=ds.sel(latitude = slice(57,20), longitude= slice(-130,-65))\n",
    "        #ds = ds.sel(step=step)\n",
    "        #print(ds)\n",
    "        wind_u = f'u{level}'\n",
    "        wind_v = f'v{level}'\n",
    "        variable = windCalc(ds[wind_u].values, ds[wind_v].values)\n",
    "        #variables = list(ds.data_vars)\n",
    "        #variable = ds[variables[0]]\n",
    "        #variable = variable.rio.write_crs(\"EPSG:4326\")\n",
    "        #variable.attrs['units'] = p_units\n",
    "        #variable = variable.metpy.quantify() \n",
    "        #variable_F = variable.metpy.convert_units('degF')\n",
    "        fig, ax = plt.subplots(figsize=(10, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "        #contour = variable_F.plot(ax=ax, transform=ccrs.PlateCarree(), vmin=-30, vmax=130, cmap=cmap)\n",
    "        #contour = ax.contourf(variable.longitude, variable.latitude, variable_F.values, transform=ccrs.PlateCarree(), levels = 32, vmin=-30, vmax=130, cmap=cmap)\n",
    "        #contour = ax.pcolormesh(ds.longitude, ds.latitude, variable, transform=ccrs.PlateCarree(), vmin=0, vmax=60, cmap=cmap_wind, shading='gouraud')\n",
    "        contour = ax.contourf(ds.longitude, ds.latitude, variable, transform=ccrs.PlateCarree(), levels=61, vmin=0, vmax=60, cmap=cmap_wind)\n",
    "        gdf_wind.plot(ax=ax, color='black', edgecolor='black', markersize=0.4, alpha=1.0, label=\"wind farms\")\n",
    "        #ds1 = ds1.coarsen(latitude=2, longitude=2, boundary='trim').mean()\n",
    "        #y, x = np.meshgrid(ds1.longitude, ds1.latitude)\n",
    "        #ax.streamplot(y, x, ds1[wind_u].values, ds1[wind_v].values, density=[0.8, 1])\n",
    "        ax.add_feature(cfeature.STATES)\n",
    "        ax.coastlines()\n",
    "        cbar = fig.colorbar(contour, shrink=1.0, orientation='horizontal', pad=0.03, aspect=60)\n",
    "        cbar.ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "        #colorbar = contour.colorbar\n",
    "        #colorbar.ax.set_position([0.78, 0.3, 0.03, 0.4])\n",
    "        time_init = pd.Timestamp(ds.time.values).strftime('%D %H')\n",
    "        time_valid = pd.Timestamp(ds.valid_time.values).strftime('%a %D %H')\n",
    "        plt.title(f\"ECMWF {level}m wind mph {time_init}Z fcst hr {step} {time_valid}Z\")\n",
    "        extents = {\n",
    "            'conus': [-130, -65, 20, 50],       # Global extent\n",
    "            'central': [-105, -85, 28, 50],     # Regional extent\n",
    "            'sc_plains': [-103, -95, 33, 39]          # Another regional extent\n",
    "            }\n",
    "        extents2 = {\n",
    "            'sc_plains': [-103, -95, 33, 39]\n",
    "            }\n",
    "        #ax.set_extent([-130, -65, 20, 50])\n",
    "        \n",
    "        for extent_version, extent in extents2.items():\n",
    "            ax.set_extent(extent)\n",
    "            plt.savefig(f\"data/images/ecmwf_plot/ecmwf_{extent_version}_{shortname}_{str(step).zfill(3)}.png\", bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from osgeo import gdal\n",
    "\n",
    "# Database connection details\n",
    "DB_HOST = 'localhost'\n",
    "DB_PORT = '5432'\n",
    "DB_NAME = 'geoserver_mosaic'\n",
    "DB_USER = 'geoserver_user'\n",
    "DB_PASS = 'geoserver'\n",
    "\n",
    "\n",
    "# Connect to the PostGIS database\n",
    "conn = psycopg2.connect(\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT,\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASS\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "def insert_metadata(file_path):\n",
    "    # Extract filename\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    # Extract date and time from filename (assuming format hrrr_wind-YYYYMMDDTHHmm.tiff)\n",
    "    date_time_str = filename.split('-')[1].split('.')[0]  # Extract '20240915T1400'\n",
    "    ingestion = f\"{date_time_str[:4]}-{date_time_str[4:6]}-{date_time_str[6:8]} {date_time_str[8:10]}:00:00\"\n",
    "    \n",
    "    # Open the TIFF file to get the bounding box (envelope)\n",
    "    ds = gdal.Open(file_path)\n",
    "    gt = ds.GetGeoTransform()\n",
    "    minx = gt[0]\n",
    "    maxx = gt[0] + (ds.RasterXSize * gt[1])\n",
    "    miny = gt[3] + (ds.RasterYSize * gt[5])\n",
    "    maxy = gt[3]\n",
    "\n",
    "    # Delete old records with the same date and hour\n",
    "    delete_query = \"DELETE FROM public.hrrr_refd WHERE ingestion = %s\"\n",
    "    cur.execute(delete_query, (ingestion,))\n",
    "    print(f\"Deleted old records for {ingestion}\")\n",
    "\n",
    "    # Insert metadata into PostGIS table\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO public.hrrr_refd (location, ingestion, the_geom)\n",
    "        VALUES (%s, %s, ST_MakeEnvelope(%s, %s, %s, %s, 3857))\n",
    "    \"\"\"\n",
    "\n",
    "    #insert_query = \"INSERT INTO IM_hrrr_refd.hrrr_refd (location, ingestion, the_geom) VALUES (%s, %s, ST_MakeEnvelope(%s, %s, %s, %s, 3857))\"\n",
    "\n",
    "\n",
    "    cur.execute(insert_query, (filename, ingestion, minx, miny, maxx, maxy))\n",
    "    print(f\"Inserted metadata for {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from osgeo import gdal\n",
    "\n",
    "def pg_conn():\n",
    "    # Database connection details\n",
    "    DB_HOST = 'localhost'\n",
    "    DB_PORT = '5432'\n",
    "    DB_NAME = 'geoserver_db'\n",
    "    DB_USER = 'geoserver_user'\n",
    "    DB_PASS = 'geoserver'\n",
    "\n",
    "    # Connect to the PostGIS database\n",
    "    conn = psycopg2.connect(\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT,\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASS\n",
    "    )\n",
    "\n",
    "    # Create a cursor object\n",
    "    cur = conn.cursor()\n",
    "    return conn, cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conn, cur = pg_conn()\n",
    "model = 'ecmwf'\n",
    "testfile = \"data/gribs/ecmwf/maxmin/ecmwf-latest.grib\"\n",
    "grbs = pygrib.open(testfile)\n",
    "for grb in grbs[1:9]:\n",
    "    shortname = grb.shortName\n",
    "    longname = grb.name\n",
    "    validDate = grb.validDate\n",
    "    analDate = grb.analDate\n",
    "    fcstHour = grb.forecastTime\n",
    "    level = grb.level\n",
    "    levtype = grb.levtype\n",
    "    typeOfLevel = grb.typeOfLevel\n",
    "    unit = grb.units\n",
    "    cfName = grb.cfVarName\n",
    "    stepType = grb.stepType\n",
    "    step = grb.step\n",
    "    p_units = grb.parameterUnits\n",
    "    ens_type = ''\n",
    "    creation_time = datetime.now()\n",
    "    fapi_root = \"/var/www/fapi/app/\"\n",
    "    fapi_filename = f\"static/data/images/{model}/{model}_{shortname}_{str(step).zfill(3)}.png\"\n",
    "    fapi_path = f\"{fapi_root}{fapi_filename}\"\n",
    "    print('shortname', shortname)\n",
    "    print('longname', longname)\n",
    "    print('initTime', analDate)\n",
    "    print('validDate', validDate)\n",
    "    print('forecastime', fcstHour)\n",
    "    print('stepType', stepType)\n",
    "    print('step', step)\n",
    "    print('creationTime', creation_time)\n",
    "\n",
    "    insert_query = \"\"\"\n",
    "        INSERT INTO model_image.image_meta (path_rel, model, wxvar, \"initTime\", \"validTime\", step_hours, \"stepType\", level, ens_type, \"creationTime\")\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        ON CONFLICT (model, wxvar, \"initTime\", \"validTime\", level, ens_type)\n",
    "        DO NOTHING;\n",
    "    \"\"\"\n",
    "    #print(insert_query, (fapi_filename, model, shortname, analDate, validDate, step, stepType, level, ens_type, creation_time))\n",
    "    cur.execute(insert_query, (fapi_filename, model, shortname, analDate, validDate, step, stepType, level, ens_type, creation_time))\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
